# Image Captioning Using YaHa

This project aims to generate captions / descriptions from images using YaHa, a novel model implemented in a Flamingo style architecture with GPT-3 as Language model and ViT as vision transformer.

- To train, run `bash train_script.sh`
- Get COCO-2017 Dataset from https://cocodataset.org/#download
- To test, download random images from internet and put in 'Test_images' folder.